{"cells":[{"metadata":{},"cell_type":"markdown","source":"**In this kernel, I have used 4 different cases with 5 algorithms to predict best possible RMSE value along with varience error**\nFollowing are the four different cases that are tried:\n1. Removing features which are multicollinear\n2. Standardising the data after removing features which are collinear\n3. Removing features with P-value greater than 0.05\n4. Removing features with P-value greater than 0.05 and standardising the data\n\nBelow are the five algorithms that are used in our anaysis:\n\n1. Linear Regression\n2. Gradient Boost Regressor\n3. AdaBoost Regressor\n4. Linear Regressor Bagging\n5. Random Forest regressor","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Information\n\nData contains technical information about different cars from which we need to predict mpg of car.\nFollowing are the information about the features:\n\n1. mpg: Miles per gallon run by car\n2. cylinders: No. of cylinders in engine\n3. displacement: engine displacement in cubic inches\n4. horsepower: Horse power of particular car\n5. weight: Dead weight of car in lbs\n6. acceleration: Time taken for car to reach from 0 mph to 60 mph\n7. model year: Year in which car was released\n8. origin: Country of origin 1 - American, 2 - European, 3 - Japenese\n9. car name: Name of car","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Importing Necessary Libraries**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import cross_val_score,KFold,train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor,RandomForestRegressor,VotingRegressor\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso, ElasticNet\nfrom sklearn.preprocessing import PolynomialFeatures\nimport statsmodels.formula.api as smf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing Data**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndf=pd.read_csv('../input/autompg-dataset/auto-mpg.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replacing the values of origin column to get better results\n\n1 to be replaced with American, 2 with European and 3 with Japan","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['origin'].replace({1:'American',2:'European',3:'Japanese'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # **Exploratory Data Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In, the above cell, even though horsepower is numerical feature, it is shown as object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['horsepower']=pd.to_numeric(df['horsepower'],errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['mpg'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution is almost normally distributed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cylinders'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Multiple peaks indicates, cylinders is discrete feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['displacement'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of cars have low to average displacements, few have very high displacements","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['horsepower'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of cars low to average horse powers. Few cars have high horse power","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['weight'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of  cars are heavy, there are very few cars which are light.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['acceleration'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"acceleration values are almostnormally distributed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax=sns.countplot(df['origin'])\nfor i in ax.patches:\n    ax.annotate('{}'.format(i.get_height()),(i.get_x()+0.3,i.get_height()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 249 cars of american origin, 79 of Japenese origin and 70 cars of European origin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax=sns.barplot(x=df['origin'],y=df['weight'].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Weight of cars of all origins are almost same","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=(df.groupby('origin')['acceleration'].median())\nprint(acc)\nacc.plot(kind='bar')\nplt.ylabel('Avg Acceleration')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Japanese origin cars have highest acceleration whereas American origin cars have least acceleration among 3 origin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hp=(df.groupby('origin')['horsepower'].median())\nprint(hp)\nhp.plot(kind='bar')\nplt.ylabel('Avg. HP')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Cars of American origin have highest horsepower. European and Japanese origin are no where near American cars in terms of horse power.\n2. Even though Japanese origin cars have highest acceleration, they have least average horsepower\n3. American origin cars have highest horse power. They outperform Japanese origin but they have lesser acceleration  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mpg=(df.groupby('origin')['mpg'].median())\nprint(mpg)\nmpg.plot(kind='bar')\nplt.ylabel('Avg Mpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"American origin cars have lowet mpg among 3 origin cars. Japanese cars have highest mpg.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax=sns.countplot(df['model year'])\nfor i in ax.patches:\n    ax.annotate('{}'.format(i.get_height()),(i.get_x()+0.3,i.get_height()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Most of the cars were introduced in the year 1973","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=df['weight'],y=df['mpg'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen that as weight increases, it requires higher amount of fuel to move as a result mpg reduces","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=df['weight'],y=df['horsepower'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we need higher horsepower, we need more number of cylinders and increase in number of increases weight of car","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=df['horsepower'],y=df['mpg'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Increase in horsepower increases weight which reduces mpg","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=df['acceleration'],y=df['horsepower'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Higher the horsepower, more no. of cylinders, hence more displacement. Higher the displacement, lesser is the time to accelerate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_mat=df.corr()\nsns.heatmap(cor_mat,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. We can observe that there is good positive correlation between displacement and number of cylinders. As number of cylinders increases displacement increases.\n2. Also there is good positive correlation between weight and number of cylinders, since increase in no. of cylinders increases dead weight of car which also increases displacement of car. Thus we can say that weight and displacement are directly correlated which is evident from above heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,vars=['mpg','cylinders','displacement','horsepower','weight','acceleration'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# **Missing Value Imputation**\nBefore using KNN imputer, let us create dummy columns for origin, model year and we will drop 'car name'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col=['origin','model year']\ndf=pd.get_dummies(data=df,drop_first=True,columns=col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('car name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp=KNNImputer(missing_values=np.nan,n_neighbors=4)\ndf1=imp.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(df1,columns=df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['horsepower'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Building**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Base Model\nx=df.drop('mpg',axis=1)\ny=df['mpg']\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_const=sm.add_constant(x_train)\nmodel=sm.OLS(y_train,x_const).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = [variance_inflation_factor(x_const.values, i) for i in range(x_const.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=x_train.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1=x.drop('horsepower',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x1,y,test_size=0.30,random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_const=sm.add_constant(x_train)\nmodel=sm.OLS(y_train,x_const).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = [variance_inflation_factor(x_const.values, i) for i in range(x_const.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=x_train.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1=x1.drop('cylinders',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x1,y,test_size=0.30,random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_const=sm.add_constant(x_train)\nmodel=sm.OLS(y_train,x_const).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = [variance_inflation_factor(x_const.values, i) for i in range(x_const.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=x_train.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1=x1.drop('displacement',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x1,y,test_size=0.30,random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_const=sm.add_constant(x_train)\nmodel=sm.OLS(y_train,x_const).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = [variance_inflation_factor(x_const.values, i) for i in range(x_const.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=x_train.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LinearRegression()\nmodel=lr.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'R^2 score for train: {lr.score(x_train, y_train)}')\nprint(f'R^2 score for test: {lr.score(x_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = cross_val_score(lr, x_train, y_train,cv=5, scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.abs(cv_results))))\nprint(np.std(np.sqrt(np.abs(cv_results)),ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(y_test,y_pred)\nrmse=np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Boosting Regressors**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GB_bias=[]\nGB_var=[]\nfor n in np.arange(1,150):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    scores=cross_val_score(GB,x_train,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    GB_bias.append(np.mean(rmse))\n    GB_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_axis=np.arange(len(GB_bias))\nplt.plot(x_axis,GB_bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_var),GB_var[np.argmin(GB_var)],GB_bias[np.argmin(GB_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_bias),GB_bias[np.argmin(GB_bias)],GB_var[np.argmin(GB_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABLR_bias=[]\nABLR_var=[]\nfor n in np.arange(1,150):\n    ABLR=AdaBoostRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(ABLR,x_train,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    ABLR_bias.append(np.mean(rmse))\n    ABLR_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_axis=np.arange(len(ABLR_bias))\nplt.plot(x_axis,ABLR_bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_bias), ABLR_bias[np.argmin(ABLR_bias)],ABLR_var[np.argmin(ABLR_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_var), ABLR_var[np.argmin(ABLR_var)],ABLR_bias[np.argmin(ABLR_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Bagging Regressors**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Bag_bias=[]\nBag_var=[]\nfor n in np.arange(1,150):\n    Bag=BaggingRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(Bag,x_train,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    Bag_bias.append(np.mean(rmse))\n    Bag_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_var),Bag_var[np.argmin(Bag_var)],Bag_bias[np.argmin(Bag_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_bias),Bag_bias[np.argmin(Bag_bias)],Bag_var[np.argmin(Bag_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_bias=[]\nRF_var=[]\nfor n in np.arange(1,150):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    scores=cross_val_score(RF,x_train,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    RF_bias.append(np.mean(rmse))\n    RF_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_bias),RF_bias[np.argmin(RF_bias)],RF_var[np.argmin(RF_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_var),RF_var[np.argmin(RF_var)],RF_bias[np.argmin(RF_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Standardising the data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=1234)\nss=StandardScaler()\nx_s=ss.fit_transform(x)\nx_trains=ss.fit_transform(x_train)\nx_tests=ss.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LinearRegression()\nmodel=lr.fit(x_trains,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'R^2 score for train: {lr.score(x_trains, y_train)}')\nprint(f'R^2 score for test: {lr.score(x_tests, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = cross_val_score(lr, x_trains, y_train,cv=5, scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.abs(cv_results))))\nprint(np.std(np.sqrt(np.abs(cv_results)),ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lr.predict(x_tests)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(y_test,y_pred)\nrmse=np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Boosting Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GB_bias=[]\nGB_var=[]\nfor n in np.arange(1,150):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    scores=cross_val_score(GB,x_trains,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    GB_bias.append(np.mean(rmse))\n    GB_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_var),GB_var[np.argmin(GB_var)],GB_bias[np.argmin(GB_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_bias),GB_bias[np.argmin(GB_bias)],GB_var[np.argmin(GB_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABLR_bias=[]\nABLR_var=[]\nfor n in np.arange(1,150):\n    ABLR=AdaBoostRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(ABLR,x_trains,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    ABLR_bias.append(np.mean(rmse))\n    ABLR_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_bias), ABLR_bias[np.argmin(ABLR_bias)],ABLR_var[np.argmin(ABLR_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_var), ABLR_var[np.argmin(ABLR_var)],ABLR_bias[np.argmin(ABLR_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Bagging Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Bag_bias=[]\nBag_var=[]\nfor n in np.arange(1,150):\n    Bag=BaggingRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(Bag,x_train,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    Bag_bias.append(np.mean(rmse))\n    Bag_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_var),Bag_var[np.argmin(Bag_var)],Bag_bias[np.argmin(Bag_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_bias),Bag_bias[np.argmin(Bag_bias)],Bag_var[np.argmin(Bag_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_bias=[]\nRF_var=[]\nfor n in np.arange(1,150):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    scores=cross_val_score(RF,x_trains,y_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    RF_bias.append(np.mean(rmse))\n    RF_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_bias),RF_bias[np.argmin(RF_bias)],RF_var[np.argmin(RF_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_var),RF_var[np.argmin(RF_var)],RF_bias[np.argmin(RF_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Elimination**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(x.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    x = x[cols]\n    Xc = sm.add_constant(x)\n    model = sm.OLS(y,Xc).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features = cols\nprint(selected_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new=x[selected_features]\nX_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train1,x_test1,y_train1,y_test1=train_test_split(X_new,y,test_size=0.30,random_state=1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LinearRegression()\nmodel=lr.fit(x_train1,y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'R^2 score for train: {lr.score(x_train1, y_train1)}')\nprint(f'R^2 score for test: {lr.score(x_test1, y_test1)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = cross_val_score(lr, x_train1, y_train1,cv=5, scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.abs(cv_results))))\nprint(np.std(np.sqrt(np.abs(cv_results)),ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lr.predict(x_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(y_test1,y_pred)\nrmse=np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Boosting Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GB_bias=[]\nGB_var=[]\nfor n in np.arange(1,150):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    scores=cross_val_score(GB,x_train1,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    GB_bias.append(np.mean(rmse))\n    GB_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_var),GB_var[np.argmin(GB_var)],GB_bias[np.argmin(GB_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_bias),GB_bias[np.argmin(GB_bias)],GB_var[np.argmin(GB_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABLR_bias=[]\nABLR_var=[]\nfor n in np.arange(1,150):\n    ABLR=AdaBoostRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(ABLR,x_train1,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    ABLR_bias.append(np.mean(rmse))\n    ABLR_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_bias), ABLR_bias[np.argmin(ABLR_bias)],ABLR_var[np.argmin(ABLR_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_var), ABLR_var[np.argmin(ABLR_var)],ABLR_bias[np.argmin(ABLR_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Bagging Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Bag_bias=[]\nBag_var=[]\nfor n in np.arange(1,150):\n    Bag=BaggingRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(Bag,x_train1,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    Bag_bias.append(np.mean(rmse))\n    Bag_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_var),Bag_var[np.argmin(Bag_var)],Bag_bias[np.argmin(Bag_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_bias),Bag_bias[np.argmin(Bag_bias)],Bag_var[np.argmin(Bag_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_bias=[]\nRF_var=[]\nfor n in np.arange(1,150):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    scores=cross_val_score(RF,x_train1,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    RF_bias.append(np.mean(rmse))\n    RF_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_bias),RF_bias[np.argmin(RF_bias)],RF_var[np.argmin(RF_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_var),RF_var[np.argmin(RF_var)],RF_bias[np.argmin(RF_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Standardising the selected features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_news=ss.fit_transform(X_new)\nx_train1s=ss.fit_transform(x_train1)\nx_test1s=ss.transform(x_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LinearRegression()\nmodel=lr.fit(x_train1s,y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'R^2 score for train: {lr.score(x_train1s, y_train1)}')\nprint(f'R^2 score for test: {lr.score(x_test1s, y_test1)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = cross_val_score(lr, x_train1s, y_train1,cv=5, scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.abs(cv_results))))\nprint(np.std(np.sqrt(np.abs(cv_results)),ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lr.predict(x_test1s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(y_test1,y_pred)\nrmse=np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Boosting Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GB_bias=[]\nGB_var=[]\nfor n in np.arange(1,150):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    scores=cross_val_score(GB,x_train1s,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    GB_bias.append(np.mean(rmse))\n    GB_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_bias),GB_bias[np.argmin(GB_bias)],GB_var[np.argmin(GB_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_var),GB_var[np.argmin(GB_var)],GB_bias[np.argmin(GB_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABLR_bias=[]\nABLR_var=[]\nfor n in np.arange(1,150):\n    ABLR=AdaBoostRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(ABLR,x_train1s,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    ABLR_bias.append(np.mean(rmse))\n    ABLR_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_bias), ABLR_bias[np.argmin(ABLR_bias)],ABLR_var[np.argmin(ABLR_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_var), ABLR_var[np.argmin(ABLR_var)],ABLR_bias[np.argmin(ABLR_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Bagging Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Bag_bias=[]\nBag_var=[]\nfor n in np.arange(1,150):\n    Bag=BaggingRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(Bag,x_train1s,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    Bag_bias.append(np.mean(rmse))\n    Bag_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_bias),Bag_bias[np.argmin(Bag_bias)],Bag_var[np.argmin(Bag_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_var),Bag_var[np.argmin(Bag_var)],Bag_bias[np.argmin(Bag_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_bias=[]\nRF_var=[]\nfor n in np.arange(1,150):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    scores=cross_val_score(RF,x_train1s,y_train1,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    RF_bias.append(np.mean(rmse))\n    RF_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_bias),RF_bias[np.argmin(RF_bias)],RF_var[np.argmin(RF_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_var),RF_var[np.argmin(RF_var)],RF_bias[np.argmin(RF_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Ridge and Lasso Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Rd=Ridge(alpha=0.5,normalize=True)\nLs=Lasso(alpha=0.1,normalize=True)\nEn=ElasticNet(alpha=0.01,l1_ratio=0.919,normalize=True)\nmodels = []\nmodels.append(('Ridge',Rd))\nmodels.append(('Lasso',Ls))\nmodels.append(('Elastic',En))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    cv_results = cross_val_score(model, x, y,cv=kfold, scoring='neg_mean_squared_error')\n    results.append(np.sqrt(np.abs(cv_results)))\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, np.mean(np.sqrt(np.abs(cv_results))),np.std(np.sqrt(np.abs(cv_results)),ddof=1)))\n   # boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    cv_results = cross_val_score(model, X_new, y,cv=kfold, scoring='neg_mean_squared_error')\n    results.append(np.sqrt(np.abs(cv_results)))\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, np.mean(np.sqrt(np.abs(cv_results))),np.std(np.sqrt(np.abs(cv_results)),ddof=1)))\n   # boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Polynomial Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_final=df.drop('mpg',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr=x_final[['displacement','horsepower','weight','acceleration']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qr=PolynomialFeatures(degree=2)\nx_qr=qr.fit_transform(x_qr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df=pd.DataFrame(x_qr)\nx_qr_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df=x_qr_df.drop(0,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx=np.arange(x_final.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.index=idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_final.index=idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df=pd.concat([x_final,x_qr_df,y],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df.drop(['displacement','horsepower','weight','acceleration'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr_df.columns=['cylinders', 'origin_European', 'origin_Japanese','model year_71',   'model year_72',   'model year_73',\n                 'model year_74',   'model year_75',   'model year_76','model year_77',   'model year_78',   'model year_79',\n                 'model year_80',   'model year_81',   'model year_82','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10',\n                 'f11','f12','f13','f14','mpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_qr=x_qr_df.drop('mpg',axis=1)\ny_qr=x_qr_df['mpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qr=LinearRegression()\nmodels = []\nmodels.append(('Ridge',Rd))\nmodels.append(('Lasso',Ls))\nmodels.append(('Elastic',En))\nmodels.append(('Quadratic',qr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    cv_results = cross_val_score(model, x_qr, y_qr,cv=kfold, scoring='neg_mean_squared_error')\n    results.append(np.sqrt(np.abs(cv_results)))\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, np.mean(np.sqrt(np.abs(cv_results))),np.std(np.sqrt(np.abs(cv_results)),ddof=1)))\n   # boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xqr_train,xqr_test,yqr_train,yqr_test=train_test_split(x_qr,y_qr,test_size=0.30,random_state=1234)\ncv_results = cross_val_score(qr, xqr_train, yqr_train,cv=5, scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.abs(cv_results))))\nprint(np.std(np.sqrt(np.abs(cv_results)),ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lr.predict(xqr_test)\nmse=mean_squared_error(yqr_test,y_pred)\nrmse=np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GB_bias=[]\nGB_var=[]\nfor n in np.arange(1,150):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    scores=cross_val_score(GB,xqr_train,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    GB_bias.append(np.mean(rmse))\n    GB_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_bias),GB_bias[np.argmin(GB_bias)],GB_var[np.argmin(GB_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_var),GB_var[np.argmin(GB_var)],GB_bias[np.argmin(GB_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABLR_bias=[]\nABLR_var=[]\nfor n in np.arange(1,150):\n    ABLR=AdaBoostRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(ABLR,xqr_train,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    ABLR_bias.append(np.mean(rmse))\n    ABLR_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_bias), ABLR_bias[np.argmin(ABLR_bias)],ABLR_var[np.argmin(ABLR_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_var), ABLR_var[np.argmin(ABLR_var)],ABLR_bias[np.argmin(ABLR_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Bagging Regressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Bag_bias=[]\nBag_var=[]\nfor n in np.arange(1,150):\n    Bag=BaggingRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(Bag,xqr_train,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    Bag_bias.append(np.mean(rmse))\n    Bag_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_bias),Bag_bias[np.argmin(Bag_bias)],Bag_var[np.argmin(Bag_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_var),Bag_var[np.argmin(Bag_var)],Bag_bias[np.argmin(Bag_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_bias=[]\nRF_var=[]\nfor n in np.arange(1,150):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    scores=cross_val_score(RF,xqr_train,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    RF_bias.append(np.mean(rmse))\n    RF_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_bias),RF_bias[np.argmin(RF_bias)],RF_var[np.argmin(RF_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_var),RF_var[np.argmin(RF_var)],RF_bias[np.argmin(RF_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Standardising the polynomial features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xqr_s=ss.fit_transform(x_qr)\nxqr_trains=ss.fit_transform(xqr_train)\nxqr_tests=ss.transform(xqr_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = cross_val_score(qr, xqr_trains, yqr_train,cv=5, scoring='neg_mean_squared_error')\nprint(np.mean(np.sqrt(np.abs(cv_results))))\nprint(np.std(np.sqrt(np.abs(cv_results)),ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=qr.predict(xqr_tests)\nmse=mean_squared_error(yqr_test,y_pred)\nrmse=np.sqrt(mse)\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GB_bias=[]\nGB_var=[]\nfor n in np.arange(1,150):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    scores=cross_val_score(GB,xqr_trains,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    GB_bias.append(np.mean(rmse))\n    GB_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_bias),GB_bias[np.argmin(GB_bias)],GB_var[np.argmin(GB_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(GB_var),GB_var[np.argmin(GB_var)],GB_bias[np.argmin(GB_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABLR_bias=[]\nABLR_var=[]\nfor n in np.arange(1,150):\n    ABLR=AdaBoostRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(ABLR,xqr_trains,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    ABLR_bias.append(np.mean(rmse))\n    ABLR_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_bias), ABLR_bias[np.argmin(ABLR_bias)],ABLR_var[np.argmin(ABLR_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(ABLR_var), ABLR_var[np.argmin(ABLR_var)],ABLR_bias[np.argmin(ABLR_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Bag_bias=[]\nBag_var=[]\nfor n in np.arange(1,150):\n    Bag=BaggingRegressor(base_estimator=lr,n_estimators=n,random_state=0)\n    scores=cross_val_score(Bag,xqr_trains,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    Bag_bias.append(np.mean(rmse))\n    Bag_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_bias),Bag_bias[np.argmin(Bag_bias)],Bag_var[np.argmin(Bag_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(Bag_var),Bag_var[np.argmin(Bag_var)],Bag_bias[np.argmin(Bag_var)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_bias=[]\nRF_var=[]\nfor n in np.arange(1,150):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    scores=cross_val_score(RF,xqr_trains,yqr_train,cv=5,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    RF_bias.append(np.mean(rmse))\n    RF_var.append(np.std(rmse,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_bias),RF_bias[np.argmin(RF_bias)],RF_var[np.argmin(RF_bias)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmin(RF_var),RF_var[np.argmin(RF_var)],RF_bias[np.argmin(RF_var)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Below are the results of all combinations:\n\n1. Removing features which are multicollinear:\n    1. Linear Regression - rmse = 3.18 (0.25)\n    2. GB Regressor - n_estimator = 21, rmse = 3.76 (0.15)\n    3. AdaBoost Regressor - n_estimator = 2, rmse = 3.26 (0.16)\n    4. Bagging LR - n_estimator = 1, rmse = 3.25 (0.16)\n    5. Random Forest - n_estimator = 93, rmse = 3.52 (0.15)\n    \n2. Removing features which are multicollinear and standardising the data:\n    1. Linear Regression - rmse = 3.19 (0.19)\n    2. GB Regressor - n_estimator = 9, rmse = 4.62 (0.22)\n    3. AdaBoost Regressor - n_estimator = 3, rmse = 3.16 (0.14)\n    4. Bagging LR - n_estimator = 135, rmse = 3.19 (0.18)\n    5. Random Forest - n_estimator = 8, rmse = 3.58 (0.42)\n    \n3. Removing features with P-value greater than 0.05:\n    1. Linear Regression - rmse = 3.198 (0.17)\n    2. GB Regressor - n_estimator = 130, rmse = 3.195 (0.58)\n    3. AdaBoost Regressor - n_estimator = 3, rmse = 3.155 (0.14)\n    4. Bagging LR - n_estimator = 62, rmse = 3.199 (0.168)\n    5. Random Forest - n_estimator = 135, rmse = 3.39 (0.46)\n    \n4. Removing Features with P-Value greater than 0.05 and standardising the data:\n    1. Linear Regression - rmse = 3.198 (0.17)\n    2. GB Regressor - n_estimator = 6, rmse = 5.176 (0.26)\n    3. AdaBoost Regressor - n_estimator = 3, rmse = 3.155 (0.14)\n    4. Bagging LR - n_estimator = 62, rmse = 3.199 (0.168)\n    5. Random Forest - n_estimator = 135, rmse = 3.395 (0.457)\n    \n5. Polynomial Features\n    1. Linear Regression - rmse = 2.84 (0.34)\n    2. GB Regressor - n_estimator = 100, rmse = 3.32 (0.30)\n    3. AdaBoost Regressor - n_estimator = 1, rmse = 3.11 (0.28)\n    4. Bagging LR - n_estimator = 116, rmse = 2.83 (0.33)\n    5. Random Forest - n_estimator = 135, rmse = 3.395 (0.457)\n    \n**It can be seen that Ada Boost regressor with features less than 0.05 has lowest RMSE, hence this can be used for our predictions**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}